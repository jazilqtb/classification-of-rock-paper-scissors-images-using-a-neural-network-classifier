# -*- coding: utf-8 -*-
"""klasifikasibatuguntingkertas

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gc650nNWzeP4HjPcoHrca17L9m1-aDoR
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

#mendownload dataset
!wget --no-check-certificate \
  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \
  -O /tmp/rockpaperscissors.zip

#melakukan ekstraksi pada file zip
import zipfile
import os

local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

#memasukkan alamat file gambar
base_dir = '/tmp/rockpaperscissors'
rock_dir = os.path.join(base_dir, 'rock')
paper_dir = os.path.join(base_dir, 'paper')
scissors_dir = os.path.join(base_dir, 'scissors')
#fungsi os.path.join hanyalah menyambungkan direktori bukan membuat
#pada tahap ini kita hanya memasukkan alamat folder rock ke dalam variabel rock_dir
#variabel rock_dir bisa ditulis dengan
#rock_dir = '/tmp/rockpaperscissors/rps-cv-images/rock'

print(len(os.listdir(rock_dir)))
print(len(os.listdir(paper_dir)))
print(len(os.listdir(scissors_dir)))

#membagi dataset menjadi train dan validation
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_dir = '/tmp/rockpaperscissors/rps-cv-images'
train_datagen = ImageDataGenerator(
                  rescale=1./255,
                  rotation_range = 30,
                  shear_range = 0.2,
                  zoom_range=0.2,
                  horizontal_flip = True,
                  fill_mode = 'nearest',
                  validation_split=0.4) #set validation split
train_generator = train_datagen.flow_from_directory(
                  train_dir,
                  target_size=(150,150),
                  batch_size = 32,
                  class_mode = 'categorical',
                  shuffle=True,
                  subset = 'training')
validation_generator = train_datagen.flow_from_directory(
                  train_dir,
                  target_size = (150,150),
                  batch_size = 32,
                  class_mode = 'categorical',
                  shuffle=True,
                  subset = 'validation')

model = tf.keras.models.Sequential([
        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),
        tf.keras.layers.MaxPooling2D(2,2),
        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2,2),
        tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2,2),
        tf.keras.layers.Conv2D(256, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2,2),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(512, activation='relu'),
        tf.keras.layers.Dense(256, activation='relu'),
        tf.keras.layers.Dense(3, activation='softmax')
])

model.summary()

model.compile(optimizer=tf.optimizers.Adam(),
              loss='categorical_crossentropy',
              metrics = ['accuracy'])

history = model.fit(train_generator,
                    validation_data = validation_generator,
                    steps_per_epoch = 15,
                    epochs = 30,
                    verbose=2,
                    validation_steps = 7
                    )